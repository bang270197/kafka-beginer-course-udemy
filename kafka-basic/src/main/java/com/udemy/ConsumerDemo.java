package com.udemy;import org.apache.kafka.clients.consumer.ConsumerRecords;import org.apache.kafka.clients.consumer.KafkaConsumer;import org.apache.kafka.clients.producer.Callback;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.clients.producer.RecordMetadata;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.Arrays;import java.util.Properties;public class ConsumerDemo {    public static final Logger logger = LoggerFactory.getLogger(ProducerDemoWithCallBack.class.getName());    public static void main(String[] args) {        logger.info("============ Starting ConsumerDemo ===========");        String groupId = "my-group";        String topic = "TOPIC-2";        Properties props = new Properties();        props.setProperty("bootstrap.servers", "127.0.0.1:9092");  // Kafka broker        props.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");        props.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");        props.put("group.id", groupId);        props.setProperty("auto.offset.reset", "earliest");        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);        consumer.subscribe(Arrays.asList(topic));        while (true) {            logger.info("========== Consuming Message ==========");            ConsumerRecords<String, String> records = consumer.poll(100);            records.forEach(record -> {                logger.info("Key: " + record.key() + ", Value: " + record.value());                logger.info("Partition: " + record.partition() + ", Offset: " + record.offset());            });        }    }}